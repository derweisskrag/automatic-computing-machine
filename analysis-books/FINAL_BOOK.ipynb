{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c66978",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This book includes everything needed to finish off the job by the 4th of June. Defense!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11f515",
   "metadata": {},
   "source": [
    "## Semen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc41db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from tomodachi_core.tomodachi.utils import expected_types\n",
    "\n",
    "# TODO: Possible to re-write as decorator (for, say, Preprocess)\n",
    "def validate(df: pd.DataFrame, rules_map: dict[str, str] = expected_types):\n",
    "    \"\"\"\n",
    "    Проверяет, соответствует ли DataFrame ожидаемой структуре и сохраняет его в файл.\n",
    "\n",
    "    :df: DataFrame для проверки\n",
    "    :param output_path: Путь для сохранения файла\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checks and maps the types of Pandas column\n",
    "    for col, expected_type in rules_map.items():\n",
    "        if col not in df.columns:\n",
    "            # print(f\"Ошибка: отсутствует столбец '{col}'\")\n",
    "            return False\n",
    "        \n",
    "        actual_type = df[col].dtype\n",
    "\n",
    "        # TODO: Rewrite using pattern match and that dictionay\n",
    "        # For now: keep the code\n",
    "        # Проверяем datetime\n",
    "        if expected_type.startswith(\"datetime\") and not np.issubdtype(actual_type, np.datetime64):\n",
    "            print(f\"Ошибка: '{col}' должен быть datetime, но имеет тип {actual_type}\")\n",
    "            return False\n",
    "        \n",
    "        # Проверяем числа (float или int)\n",
    "        if expected_type == \"float64\" and not np.issubdtype(actual_type, np.floating):\n",
    "            # print(f\"Ошибка: '{col}' должен быть float64, но имеет тип {actual_type}\")\n",
    "            return False\n",
    "        \n",
    "        if expected_type == \"int64\" and not np.issubdtype(actual_type, np.integer):\n",
    "            # print(f\"Ошибка: '{col}' должен быть int64, но имеет тип {actual_type}\")\n",
    "            return False\n",
    "        \n",
    "        # Проверяем строки (object)\n",
    "        if expected_type == \"object\" and not np.issubdtype(actual_type, np.object_):\n",
    "            # print(f\"Ошибка: '{col}' должен быть строкой (object), но имеет тип {actual_type}\")\n",
    "            return False\n",
    "\n",
    "    # print(\"DataFrame соответствует ожидаемой структуре.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f932c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "class WeatherImpactModel:\n",
    "    \"\"\"\n",
    "    The linear regression model for prediction Power Output based on all features\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame = None, csv_file_path: str = None):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.df = None\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.feature_importances = None\n",
    "\n",
    "\n",
    "    # for machine learning (formulas)\n",
    "    # A/B tests\n",
    "    def adding_groups(self):\n",
    "        self.df['T-WG'] = self.df['Wind_Gust']*self.df['Temperature'] # Wind Gust x Temperature\n",
    "        self.df['H-WG'] = self.df['Wind_Gust']*self.df['Humidity'] # Wind Gust x Humidity\n",
    "        self.df['CC-WG'] = self.df['Wind_Gust']*self.df['Cloud_Cover'] # Wind Gust x Cloud Cover\n",
    "        self.df['SR-WG'] = self.df['Wind_Gust']*self.df['Solar_Radiation'] # Wind Gust x Solar Radiation\n",
    "        self.df['T-WS'] = self.df['Wind_Speed']*self.df['Temperature'] # Wind Speed x Temperature\n",
    "        self.df['H-WS'] = self.df['Wind_Speed']*self.df['Humidity'] # Wind Speed x Humidity\n",
    "        self.df['CC-WS'] = self.df['Wind_Speed']*self.df['Cloud_Cover'] # Wind Speed x Cloud Cover\n",
    "        self.df['SR-WS'] = self.df['Wind_Speed']*self.df['Solar_Radiation'] # Wind Speed x Solar Radiation\n",
    "        \n",
    "    \n",
    "\n",
    "    # Model creation \n",
    "    # NB! Our data is\n",
    "    def create_model(self, check_r2_score=True):\n",
    "        X = self.df[['T-WG', 'H-WG', 'CC-WG', 'SR-WG', 'T-WS', 'H-WS', 'CC-WS', 'SR-WS']]\n",
    "        y = self.df['Power_Output']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.model = GradientBoostingRegressor(random_state=42)\n",
    "        self.model.fit(X_train, y_train)\n",
    "        if check_r2_score:\n",
    "            y_pred = self.model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            print(f\"R²: {r2:.3f}\")\n",
    "\n",
    "    def get_results(self):\n",
    "        self.feature_names = self.model.feature_names_in_\n",
    "        self.feature_importances = self.model.feature_importances_\n",
    "\n",
    "    def save_results(self, output_csv=\"weather_condition_importances.csv\"):\n",
    "        feature_df = pd.DataFrame({\n",
    "            \"Feature\": self.feature_names,\n",
    "            \"Importance\": self.feature_importances\n",
    "        })\n",
    "        feature_df.to_csv(output_csv, index=False)\n",
    "        return feature_df  # Optional: return it for further use\n",
    "\n",
    "\n",
    "    def visualize(self, output_png=\"results.png\"):\n",
    "        sorted_idx = np.argsort(self.feature_importances)[::-1]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(x=self.feature_importances[sorted_idx], y=self.feature_names[sorted_idx], palette='viridis')\n",
    "        plt.title('Feature Importance in GradientBoostingRegressor Model')\n",
    "        plt.xlabel('Significance')\n",
    "        plt.ylabel('Feature')\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(output_png)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def run_analysis(self, save_results=True, visualize=True):\n",
    "        self.load_data()\n",
    "        self.adding_groups()\n",
    "        self.create_model(check_r2_score=True) # If R² > 0.8 - model works very good\n",
    "        self.get_results()\n",
    "\n",
    "        if save_results:\n",
    "            self.save_results()\n",
    "        if visualize:\n",
    "            self.visualize()\n",
    "\n",
    "        if len(self.feature_names) != len(self.feature_importances):\n",
    "            raise ValueError\n",
    "        results = {name: imp for name, imp in zip(self.feature_names, self.feature_importances)}\n",
    "\n",
    "        return results"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
